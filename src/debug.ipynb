{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '2021年夏季无袖连衣裙酒红色高领', 'key_attr': {'袖长': '无袖', '领型': '高领'}, 'match': {'图文': 1, '袖长': 1, '领型': 1}}\n",
      "{'领型': [['高领', '半高领', '立领'], ['连帽', '可脱卸帽'], ['翻领', '衬衫领', 'POLO领', '方领', '娃娃领', '荷叶领'], ['双层领'], ['西装领'], ['U型领'], ['一字领'], ['围巾领'], ['堆堆领'], ['V领'], ['棒球领'], ['圆领'], ['斜领'], ['亨利领']], '袖长': [['短袖', '五分袖'], ['九分袖', '长袖'], ['七分袖'], ['无袖']], '衣长': [['超短款', '短款', '常规款'], ['长款', '超长款'], ['中长款']], '版型': [['修身型', '标准型'], ['宽松型']], '裙长': [['短裙', '超短裙'], ['中裙', '中长裙'], ['长裙']], '穿着方式': [['套头'], ['开衫']], '类别': [['手提包'], ['单肩包'], ['斜挎包'], ['双肩包']], '裤型': [['O型裤', '锥形裤', '哈伦裤', '灯笼裤'], ['铅笔裤', '直筒裤', '小脚裤'], ['工装裤'], ['紧身裤'], ['背带裤'], ['喇叭裤', '微喇裤'], ['阔腿裤']], '裤长': [['短裤'], ['五分裤'], ['七分裤'], ['九分裤', '长裤']], '裤门襟': [['松紧'], ['拉链'], ['系带']], '闭合方式': [['松紧带'], ['拉链'], ['套筒', '套脚', '一脚蹬'], ['系带'], ['魔术贴'], ['搭扣']], '鞋帮高度': [['高帮', '中帮'], ['低帮']]}\n"
     ]
    }
   ],
   "source": [
    "# 测试文本替换\n",
    "from replace import replace_entry,attr_dict\n",
    "data_entry = {\"title\": \"2021年夏季无袖连衣裙酒红色立领\", \"key_attr\": {\"袖长\": \"无袖\", \"领型\": \"立领\"}, \"match\": {\"图文\": 1, \"袖长\": 1, \"领型\": 1}}\n",
    "tmp = replace_entry(data_entry)\n",
    "print(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'领型': ['高领', '连帽', '翻领', '双层领', '西装领', 'U型领', '一字领', '围巾领', '堆堆领', 'V领', '棒球领', '圆领', '斜领', '亨利领'], '袖长': ['短袖', '九分袖', '七分袖', '无袖'], '衣长': ['超短款', '长款', '中长款'], '版型': ['修身型', '宽松型'], '裙长': ['短裙', '中裙', '长裙'], '穿着方式': ['套头', '开衫'], '类别': ['手提包', '单肩包', '斜挎包', '双肩包'], '裤型': ['O型裤', '铅笔裤', '工装裤', '紧身裤', '背带裤', '喇叭裤', '阔腿裤'], '裤长': ['短裤', '五分裤', '七分裤', '九分裤'], '裤门襟': ['松紧', '拉链', '系带'], '闭合方式': ['松紧带', '拉链', '套筒', '系带', '魔术贴', '搭扣'], '鞋帮高度': ['高帮', '低帮']}\n",
      "dict_keys(['领型', '袖长', '衣长', '版型', '裙长', '穿着方式', '类别', '裤型', '裤长', '裤门襟', '闭合方式', '鞋帮高度'])\n"
     ]
    }
   ],
   "source": [
    "tmp_dict ={}\n",
    "for attr_name,attr_vals in attr_dict.items():\n",
    "    tmp_list = []\n",
    "    for attr_val in attr_vals:\n",
    "        tmp_list.append(attr_val[0])\n",
    "    tmp_dict[attr_name] = tmp_list\n",
    "print(tmp_dict)\n",
    "print(tmp_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [00:58, 858.63it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative sample size:47008,positive_sample size:50000,ratio:0.000\n"
     ]
    }
   ],
   "source": [
    "from gen_neg_sample import generate_neg_samples\n",
    "\n",
    "generate_neg_samples(data_path =\"data/train_fine.txt\",res_data_dir=\"data/neg_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"data/train_coarse.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    cnt = 0\n",
    "    for line in f:\n",
    "        t = json.dumps(line)\n",
    "        print(t)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94016\n"
     ]
    }
   ],
   "source": [
    "print(47008/50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "97008it [00:02, 37344.79it/s]\n",
      "  0%|          | 1/97008 [00:00<26:07, 61.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021年春季喇叭裤牛仔裤蓝色常规厚度九分裤女装\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试dataset\n",
    "# from model import Model\n",
    "from dataset import TrainDataSet\n",
    "from tqdm import  tqdm\n",
    "# model = Model()\n",
    "# tokenize = lambda x:model.tokenizer(x)\n",
    "input_filename =\"data/neg_data/text_data.txt\"\n",
    "img_dict_path = \"data/neg_data/img_dict.txt\"\n",
    "tokenize = lambda x:x\n",
    "ds = TrainDataSet(input_filename,img_dict_path,tokenize,is_train =True)\n",
    "max_text_len = 0\n",
    "cnt = 0\n",
    "for d in tqdm(ds):\n",
    "    if cnt>=1:break\n",
    "    img_feature,text,label = d\n",
    "    max_text_len = max(max_text_len,len(text))\n",
    "    print(text)\n",
    "    cnt+=1\n",
    "print(max_text_len) # 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97008/97008 [00:07<00:00, 12370.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_text_len = 0\n",
    "for d in tqdm(ds):\n",
    "    img_feature,text,label = d\n",
    "    max_text_len = max(max_text_len,len(text))\n",
    "print(max_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "97008it [00:01, 91778.76it/s] \n",
      "  0%|          | 1/97008 [00:00<1:06:12, 24.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_feature torch.Size([2048])\n",
      "text {'input_ids': tensor([[ 101, 9960, 2399, 3217, 2108, 1589, 1375, 6175, 4281,  798, 6175, 5905,\n",
      "         5682, 2382, 6226, 1331, 2428,  736, 1146, 6175, 1957, 6163,  102,    0,\n",
      "            0,    0,    0,    0,    0,    0,    0,    0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0]])}\n",
      "torch.Size([1, 32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 测试dataset\n",
    "from model import Model\n",
    "from dataset import TrainDataSet\n",
    "from tqdm import  tqdm\n",
    "model = Model()\n",
    "tokenize = lambda x:model.tokenize(x)\n",
    "input_filename =\"data/neg_data/text_data.txt\"\n",
    "img_dict_path = \"data/neg_data/img_dict.txt\"\n",
    "ds = TrainDataSet(input_filename,img_dict_path,tokenize,is_train =True)\n",
    "\n",
    "cnt = 0\n",
    "for d in tqdm(ds):\n",
    "    if cnt>=1:break\n",
    "    img_feature,text,label = d\n",
    "    print(\"img_feature\",img_feature.shape) # (bs,2048)\n",
    "    print(\"text\",text)\n",
    "    print(text[\"input_ids\"].shape) # (bs,1,32)\n",
    "    cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1., -1.],\n",
      "        [ 2.,  2.],\n",
      "        [-1.,  3.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "t = [torch.Tensor([1,2,-1]),torch.Tensor([-1,2,3])]\n",
    "t = torch.stack(t,dim=1)\n",
    "print(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.049684946647457e-05\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "e = 2000 - 800\n",
    "es = 1363 * 5 -800\n",
    "base_lr = 1e-4\n",
    "t = 0.5 * base_lr * (1 + np.cos(e/es * np.pi)) \n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ True, False, False, False, False],\n",
      "        [False,  True, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1,0,1,0,1],\n",
    "                [1,1,0,0,0]]) # (bs,class_num)\n",
    "# 1  0  1  0  1\n",
    "# 1  1  0  0  0\n",
    "\n",
    "# 1| 0  0  0  0\n",
    "# 0  1| 0  1  1\n",
    "b = torch.Tensor([[1,0,0,0,0],\n",
    "                [0,1,0,1,1]]) # (bs_class_num)\n",
    "c = (a==b).float()\n",
    "# print(torch.nonzero(a))\n",
    "# print(torch.nonzero(b))\n",
    "\n",
    "print(a+b==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8ee65edac6e753382670ef3d12ed394f5e8d8069bdfe339d3d2a95e0361efe5d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('gaiic_track1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
